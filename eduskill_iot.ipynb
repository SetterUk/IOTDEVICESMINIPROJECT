{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "566b1e00-12ea-4140-85b6-9addec9ac4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully downloaded to: C:\\Users\\Acer\\.cache\\kagglehub\\datasets\\rabieelkharoua\\predict-smart-home-device-efficiency-dataset\\versions\\1\n",
      "Files in the dataset: ['smart_home_device_usage_data.csv']\n",
      "Successfully read smart_home_device_usage_data.csv\n",
      "   UserID       DeviceType  UsageHoursPerDay  EnergyConsumption  \\\n",
      "0       1    Smart Speaker         15.307188           1.961607   \n",
      "1       2           Camera         19.973343           8.610689   \n",
      "2       3  Security System         18.911535           2.651777   \n",
      "3       4           Camera          7.011127           2.341653   \n",
      "4       5           Camera         22.610684           4.859069   \n",
      "\n",
      "   UserPreferences  MalfunctionIncidents  DeviceAgeMonths  SmartHomeEfficiency  \n",
      "0                1                     4               36                    1  \n",
      "1                1                     0               29                    1  \n",
      "2                1                     0               20                    1  \n",
      "3                0                     3               15                    0  \n",
      "4                1                     3               36                    1  \n"
     ]
    }
   ],
   "source": [
    "# Install kagglehub if not already installed\n",
    "!pip install kagglehub -q\n",
    "\n",
    "import kagglehub\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Download the dataset\n",
    "try:\n",
    "    path = kagglehub.dataset_download(\"rabieelkharoua/predict-smart-home-device-efficiency-dataset\")\n",
    "    print(f\"Dataset successfully downloaded to: {path}\")\n",
    "    \n",
    "    # List the files in the downloaded directory\n",
    "    files = os.listdir(path)\n",
    "    print(f\"Files in the dataset: {files}\")\n",
    "    \n",
    "    # Read the CSV file(s)\n",
    "    # Assuming there's a CSV file in the dataset - adjust the filename based on what's in 'files'\n",
    "    if files:  # Check if there are any files\n",
    "        # Look for CSV files\n",
    "        csv_files = [f for f in files if f.endswith('.csv')]\n",
    "        \n",
    "        if csv_files:\n",
    "            # Read the first CSV file found\n",
    "            file_path = os.path.join(path, csv_files[0])\n",
    "            data = pd.read_csv(file_path)\n",
    "            print(f\"Successfully read {csv_files[0]}\")\n",
    "            print(data.head())  # Display the first few rows\n",
    "        else:\n",
    "            print(\"No CSV files found in the dataset.\")\n",
    "    else:\n",
    "        print(\"No files found in the downloaded dataset.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c8967f6-dd93-4ceb-942c-cc87e6ee5e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f11375f9-1241-4d45-b72e-8ff544c696b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Problem Definition: Predict smart home device efficiency and optimize energy consumption\n",
      "\n",
      "2. Data Collection and Understanding\n"
     ]
    }
   ],
   "source": [
    "# 1. Problem Definition\n",
    "\"\"\"\n",
    "Problem: Predict smart home device efficiency and optimize energy consumption\n",
    "Objectives:\n",
    "- Analyze patterns in smart home device usage\n",
    "- Identify factors affecting energy consumption\n",
    "- Build a model to predict device efficiency\n",
    "- Provide recommendations for energy optimization\n",
    "\"\"\"\n",
    "print(\"1. Problem Definition: Predict smart home device efficiency and optimize energy consumption\")\n",
    "\n",
    "# 2. Data Collection and Understanding\n",
    "print(\"\\n2. Data Collection and Understanding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08f65e5b-9c20-4da1-97cf-71b72a3c796e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values handled.\n",
      "Target column not found. Please specify the target column.\n",
      "Available columns: ['UserID', 'DeviceType', 'UsageHoursPerDay', 'EnergyConsumption', 'UserPreferences', 'MalfunctionIncidents', 'DeviceAgeMonths', 'SmartHomeEfficiency']\n"
     ]
    }
   ],
   "source": [
    "# Fill numerical columns with mean\n",
    "# Need to define numerical columns first\n",
    "numerical_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "for col in numerical_cols:\n",
    "    if data[col].isnull().sum() > 0:\n",
    "        data[col].fillna(data[col].mean(), inplace=True)\n",
    "            \n",
    "# Fill categorical columns with mode\n",
    "cat_cols = data.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols:\n",
    "    if data[col].isnull().sum() > 0:\n",
    "        data[col].fillna(data[col].mode()[0], inplace=True)\n",
    "            \n",
    "print(\"Missing values handled.\")\n",
    "        \n",
    "# 2. Identify features and target\n",
    "# Assuming the target is 'efficiency' or similar - adjust as needed based on actual column names\n",
    "possible_targets = ['efficiency', 'device_efficiency', 'energy_efficiency']\n",
    "target_col = None\n",
    "        \n",
    "for col in possible_targets:\n",
    "    if col in data.columns:\n",
    "        target_col = col\n",
    "        break\n",
    "        \n",
    "if target_col is None:\n",
    "    print(\"Target column not found. Please specify the target column.\")\n",
    "    # Display columns to help identify the target\n",
    "    print(\"Available columns:\", data.columns.tolist())\n",
    "else:\n",
    "    X = data.drop(target_col, axis=1)\n",
    "    y = data[target_col]\n",
    "            \n",
    "    # 3. Identify categorical and numerical features\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "    numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "            \n",
    "    print(f\"Target column: {target_col}\")\n",
    "    print(f\"Categorical features: {categorical_cols}\")\n",
    "    print(f\"Numerical features: {numerical_cols}\")\n",
    "            \n",
    "    # 4. Create preprocessing pipeline\n",
    "    numerical_transformer = StandardScaler()\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "            \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08e9c189-f1af-403b-87e8-17b65e338382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data split into training set (80 samples) and test set (20 samples)\n",
      "Processed training data shape: (80, 5)\n",
      "Processed test data shape: (20, 5)\n",
      "Preprocessor saved as 'preprocessor.joblib'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump\n",
    "\n",
    "np.random.seed(42)\n",
    "X = pd.DataFrame({\n",
    "    'numeric_feature1': np.random.normal(0, 1, 100),\n",
    "    'numeric_feature2': np.random.normal(0, 1, 100),\n",
    "    'categorical_feature': np.random.choice(['A', 'B', 'C'], 100)\n",
    "})\n",
    "y = np.random.randint(0, 2, 100)  # Binary target for example\n",
    "\n",
    "# Define preprocessor\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# 5. Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"\\nData split into training set ({X_train.shape[0]} samples) and test set ({X_test.shape[0]} samples)\")\n",
    "\n",
    "# 6. Apply preprocessing\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "print(f\"Processed training data shape: {X_train_processed.shape}\")\n",
    "print(f\"Processed test data shape: {X_test_processed.shape}\")\n",
    "\n",
    "# 7. Save preprocessor for later use\n",
    "dump(preprocessor, 'preprocessor.joblib')\n",
    "print(\"Preprocessor saved as 'preprocessor.joblib'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699eb8de-711e-4d6a-8204-144053604095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
